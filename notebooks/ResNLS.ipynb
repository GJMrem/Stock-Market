{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [ArXiv](https://arxiv.org/pdf/2312.01020)\n",
    "* [GitHub](https://github.com/Yuanzhe-Jia/ResNLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Cannot set a deleted experiment 'Stock Market Predictions' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_theme(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaper\u001b[39m\u001b[38;5;124m\"\u001b[39m, rc\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m4\u001b[39m)})\n\u001b[0;32m----> 3\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStock Market Predictions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResNLS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/time-series-env/lib/python3.12/site-packages/mlflow/tracking/fluent.py:182\u001b[0m, in \u001b[0;36mset_experiment\u001b[0;34m(experiment_name, experiment_id)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    177\u001b[0m                 message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment with ID \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    178\u001b[0m                 error_code\u001b[38;5;241m=\u001b[39mRESOURCE_DOES_NOT_EXIST,\n\u001b[1;32m    179\u001b[0m             )\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m experiment\u001b[38;5;241m.\u001b[39mlifecycle_stage \u001b[38;5;241m!=\u001b[39m LifecycleStage\u001b[38;5;241m.\u001b[39mACTIVE:\n\u001b[0;32m--> 182\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    183\u001b[0m             message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    184\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a deleted experiment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m as the active\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m experiment. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can restore the experiment, or permanently delete the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment to create a new one.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m             ),\n\u001b[1;32m    189\u001b[0m             error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    190\u001b[0m         )\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _active_experiment_id\n\u001b[1;32m    193\u001b[0m _active_experiment_id \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39mexperiment_id\n",
      "\u001b[0;31mMlflowException\u001b[0m: Cannot set a deleted experiment 'Stock Market Predictions' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one."
     ]
    }
   ],
   "source": [
    "sns.set_theme(\"paper\", rc={\"figure.figsize\": (16, 4)})\n",
    "\n",
    "mlflow.set_experiment(\"Stock Market Predictions\")\n",
    "mlflow.start_run(run_name='ResNLS')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/SSEC.csv\")\n",
    "data = pd.DataFrame(pd.to_numeric(df[\"Close\"]))\n",
    "dataset = np.reshape(data.values, (df.shape[0], 1))\n",
    "\n",
    "# normalise the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when sequence length is 5, data shape: (3088, 1, 5) (3088,) (310, 1, 5) (310,)\n"
     ]
    }
   ],
   "source": [
    "def split_data(dataset, train_day, predict_day):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(train_day, len(dataset)-predict_day+1):\n",
    "        x.append(dataset[i-train_day : i, 0])\n",
    "        y.append(dataset[i+predict_day-1, 0])\n",
    "    return x, y\n",
    "\n",
    "# x => data from previous days; y => data in the next day\n",
    "def reshape_data(train_data, test_data, days):\n",
    "    x_train, y_train = split_data(train_data, days, 1)\n",
    "    x_test, y_test = split_data(test_data, days, 1)\n",
    "    # convert data into numpy arrays\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "    # reshape the data for neural network training\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# create the scaled training data set\n",
    "training_data_len = math.ceil(len(dataset) * 0.9087)\n",
    "train_data = scaled_data[0:training_data_len, :]\n",
    "#print(data[:train_data.shape[0]].tail())\n",
    "\n",
    "# create the scaled test data set\n",
    "test_data = scaled_data[training_data_len-5: , :]\n",
    "\n",
    "# use 5 consecutive trading days as the unit step size sliding through the stock price data\n",
    "x_train_5, y_train_5, x_test_5, y_test_5 = reshape_data(train_data, test_data, 5)\n",
    "print(\"when sequence length is 5, data shape:\", x_train_5.shape, y_train_5.shape, x_test_5.shape, y_test_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 5; n_hidden = 64\n",
    "\n",
    "class ResNLS(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResNLS, self).__init__()\n",
    "\n",
    "        # intialise weights of the attention mechanism\n",
    "        self.weight = nn.Parameter(torch.zeros(1)).to(device)\n",
    "\n",
    "        # intialise cnn structure\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=n_hidden, kernel_size=3, stride=1, padding=1), # ((5 + 1*2 - 3)/1 + 1) = 5\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(n_hidden, eps=1e-5),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv1d(in_channels=n_hidden, out_channels=n_hidden, kernel_size=3, stride=1, padding=1), # ((5 + 1*2 - 3)/1 + 1) = 5\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(n_hidden, eps=1e-5),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_input * n_hidden, n_input)\n",
    "        )\n",
    "\n",
    "        # intialise lstm structure\n",
    "        self.lstm = nn.LSTM(n_input, n_hidden, batch_first=True, bidirectional=False)\n",
    "        self.linear = nn.Linear(n_hidden, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        cnn_output = self.cnn(x)\n",
    "        cnn_output = cnn_output.view(-1, 1, n_input)\n",
    "\n",
    "        residuals = x + self.weight * cnn_output\n",
    "\n",
    "        _, (h_n, _)  = self.lstm(x)\n",
    "        y_hat = self.linear(h_n[0,:,:])\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  50, train loss: 0.0002, val loss: 0.0002\n",
      "Epoch: 100, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 150, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 200, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 250, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 300, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 350, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 400, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 450, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 500, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 550, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 600, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 650, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 700, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 750, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 800, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 850, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 900, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 950, train loss: 0.0001, val loss: 0.0001\n",
      "Epoch: 1000, train loss: 0.0001, val loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "##################### model training #####################\n",
    "\n",
    "# prepare validation data\n",
    "val_input = torch.tensor(x_test_5, dtype=torch.float).to(device)\n",
    "val_target = torch.tensor(y_test_5, dtype=torch.float).to(device)\n",
    "\n",
    "# initialization\n",
    "epochs = 50; batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# model instance\n",
    "model = ResNLS().to(device)\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# mini-batch training\n",
    "if x_train_5.shape[0] % batch_size == 0:\n",
    "    batch_num = int(x_train_5.shape[0] / batch_size)\n",
    "else:\n",
    "    batch_num = int(x_train_5.shape[0] / batch_size) + 1\n",
    "\n",
    "params = {\n",
    "    \"num_epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning rate\": learning_rate,\n",
    "    \"objective\": type(criterion).__name__,\n",
    "    \"optimizer\": type(optimizer).__name__,\n",
    "    \"hidden size\": n_hidden,\n",
    "    \"sequence length\": n_input \n",
    "}\n",
    "mlflow.log_params(params)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for j in range(batch_num):\n",
    "\n",
    "        # prepare training data\n",
    "        train_input = torch.tensor(x_train_5[j * batch_size : (j+1) * batch_size], dtype=torch.float).to(device)\n",
    "        train_targe = torch.tensor(y_train_5[j * batch_size : (j+1) * batch_size], dtype=torch.float).to(device)\n",
    "\n",
    "        # training\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        train_output = model(train_input)\n",
    "        train_loss = criterion(train_output, train_targe.unsqueeze(-1))\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        mlflow.log_metric(\"train loss\", train_loss.item(), step=epoch+1)\n",
    "                  \n",
    "    if (epoch+1) % (epochs/20) == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_output = model(val_input)\n",
    "            val_loss = criterion(val_output, val_target.unsqueeze(-1))   \n",
    "            mlflow.log_metric(\"val loss\", val_loss.item(), step=epoch+1)        \n",
    "            print(\"Epoch: {:>3}, train loss: {:.4f}, val loss: {:.4f}\".format(epoch+1, train_loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'ResNLS'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:25.57   MSE: 1191.36   RMSE:34.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'ResNLS'.\n"
     ]
    }
   ],
   "source": [
    "##################### model validation #####################\n",
    "\n",
    "# get the model predicted price values\n",
    "predictions = model(val_input)\n",
    "predictions = scaler.inverse_transform(predictions.cpu().detach().numpy())\n",
    "# plot the stock price\n",
    "train = data[:training_data_len]\n",
    "valid = data[training_data_len:].copy()\n",
    "valid[\"Predictions\"] = predictions\n",
    "\n",
    "mlflow.pytorch.log_model(\n",
    "    registered_model_name = \"ResNLS\",\n",
    "    artifact_path = \"ResNLS\",\n",
    "    pytorch_model = model,\n",
    "    input_example = val_input.cpu().detach().numpy(),\n",
    "    signature = infer_signature(val_input.cpu().detach().numpy(), predictions)\n",
    ")\n",
    "\n",
    "y = np.array(valid[\"Close\"])\n",
    "y_hat = np.array(valid[\"Predictions\"])\n",
    "mae = metrics.mean_absolute_error(y_hat, y)\n",
    "mse = metrics.mean_squared_error(y_hat, y)\n",
    "rmse = metrics.mean_squared_error(y_hat, y) ** 0.5\n",
    "\n",
    "mlflow.log_metrics({\n",
    "    \"mae\": mae,\n",
    "    \"mse\": mse,\n",
    "    \"rmse\": rmse\n",
    "})\n",
    "\n",
    "mlflow.end_run()\n",
    "print(\"MAE:{:.2F}   MSE: {:.2f}   RMSE:{:.2F}\".format(mae, mse, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (time-series-env)",
   "language": "python",
   "name": "time-series-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
